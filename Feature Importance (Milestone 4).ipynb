{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9uy2XfUrXMwj"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas\n","import time\n","import random\n","import matplotlib\n","import sklearn.linear_model\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","import scipy.stats\n","import matplotlib.offsetbox as offsetbox\n","from matplotlib.ticker import StrMethodFormatter\n","import imageio\n","import PIL\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from itertools import product\n","from joblib import load\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error,mean_absolute_error\n","from sklearn import linear_model\n","from sklearn.preprocessing import PolynomialFeatures"]},{"cell_type":"code","source":["data_new = pandas.read_pickle(\"./pickeddata.pkl\")\n","data_new"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"XckvysLAQs22","executionInfo":{"status":"ok","timestamp":1702088400253,"user_tz":360,"elapsed":15,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"813ceffb-8063-49d7-d790-d81b9e7c36a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Date for US Imports and Exports  \\\n","0                           9-Nov-01   \n","1                          16-Nov-01   \n","2                          23-Nov-01   \n","3                          30-Nov-01   \n","4                           7-Dec-01   \n","...                              ...   \n","1137                       25-Aug-23   \n","1138                        1-Sep-23   \n","1139                        8-Sep-23   \n","1140                       15-Sep-23   \n","1141                       22-Sep-23   \n","\n","      Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)  \\\n","0                                                 10772                                    \n","1                                                 10243                                    \n","2                                                  9576                                    \n","3                                                 11170                                    \n","4                                                  9885                                    \n","...                                                 ...                                    \n","1137                                              -1684                                    \n","1138                                              -2593                                    \n","1139                                                431                                    \n","1140                                              -2290                                    \n","1141                                              -1706                                    \n","\n","      Weekly U.S. Exports of Crude Oil (Thousand Barrels per Day)  \\\n","0                                                  9639             \n","1                                                  8879             \n","2                                                  8187             \n","3                                                  9856             \n","4                                                  8966             \n","...                                                 ...             \n","1137                                               2089             \n","1138                                               1838             \n","1139                                               4492             \n","1140                                               1450             \n","1141                                               3217             \n","\n","      Weekly U.S. Exports of Total Petroleum Products (Thousand Barrels per Day)  \\\n","0                                                  1133                            \n","1                                                  1364                            \n","2                                                  1389                            \n","3                                                  1314                            \n","4                                                   919                            \n","...                                                 ...                            \n","1137                                              -3773                            \n","1138                                              -4432                            \n","1139                                              -4061                            \n","1140                                              -3741                            \n","1141                                              -4923                            \n","\n","     Date for Retail Gas Price  \\\n","0                    12-Nov-01   \n","1                    19-Nov-01   \n","2                    26-Nov-01   \n","3                     3-Dec-01   \n","4                    10-Dec-01   \n","...                        ...   \n","1137                 28-Aug-23   \n","1138                  4-Sep-23   \n","1139                 11-Sep-23   \n","1140                 18-Sep-23   \n","1141                 25-Sep-23   \n","\n","      Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)  \\\n","0                                                 1.224                                     \n","1                                                 1.208                                     \n","2                                                 1.168                                     \n","3                                                 1.149                                     \n","4                                                 1.136                                     \n","...                                                 ...                                     \n","1137                                              3.931                                     \n","1138                                              3.925                                     \n","1139                                              3.941                                     \n","1140                                              4.001                                     \n","1141                                              3.963                                     \n","\n","      Season  \n","0     autumn  \n","1     autumn  \n","2     autumn  \n","3     autumn  \n","4     winter  \n","...      ...  \n","1137  summer  \n","1138  autumn  \n","1139  autumn  \n","1140  autumn  \n","1141  autumn  \n","\n","[1142 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-bf785b72-22d4-4daa-85ef-9034e353e427\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date for US Imports and Exports</th>\n","      <th>Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)</th>\n","      <th>Weekly U.S. Exports of Crude Oil (Thousand Barrels per Day)</th>\n","      <th>Weekly U.S. Exports of Total Petroleum Products (Thousand Barrels per Day)</th>\n","      <th>Date for Retail Gas Price</th>\n","      <th>Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)</th>\n","      <th>Season</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9-Nov-01</td>\n","      <td>10772</td>\n","      <td>9639</td>\n","      <td>1133</td>\n","      <td>12-Nov-01</td>\n","      <td>1.224</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>16-Nov-01</td>\n","      <td>10243</td>\n","      <td>8879</td>\n","      <td>1364</td>\n","      <td>19-Nov-01</td>\n","      <td>1.208</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23-Nov-01</td>\n","      <td>9576</td>\n","      <td>8187</td>\n","      <td>1389</td>\n","      <td>26-Nov-01</td>\n","      <td>1.168</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30-Nov-01</td>\n","      <td>11170</td>\n","      <td>9856</td>\n","      <td>1314</td>\n","      <td>3-Dec-01</td>\n","      <td>1.149</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7-Dec-01</td>\n","      <td>9885</td>\n","      <td>8966</td>\n","      <td>919</td>\n","      <td>10-Dec-01</td>\n","      <td>1.136</td>\n","      <td>winter</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1137</th>\n","      <td>25-Aug-23</td>\n","      <td>-1684</td>\n","      <td>2089</td>\n","      <td>-3773</td>\n","      <td>28-Aug-23</td>\n","      <td>3.931</td>\n","      <td>summer</td>\n","    </tr>\n","    <tr>\n","      <th>1138</th>\n","      <td>1-Sep-23</td>\n","      <td>-2593</td>\n","      <td>1838</td>\n","      <td>-4432</td>\n","      <td>4-Sep-23</td>\n","      <td>3.925</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>1139</th>\n","      <td>8-Sep-23</td>\n","      <td>431</td>\n","      <td>4492</td>\n","      <td>-4061</td>\n","      <td>11-Sep-23</td>\n","      <td>3.941</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>1140</th>\n","      <td>15-Sep-23</td>\n","      <td>-2290</td>\n","      <td>1450</td>\n","      <td>-3741</td>\n","      <td>18-Sep-23</td>\n","      <td>4.001</td>\n","      <td>autumn</td>\n","    </tr>\n","    <tr>\n","      <th>1141</th>\n","      <td>22-Sep-23</td>\n","      <td>-1706</td>\n","      <td>3217</td>\n","      <td>-4923</td>\n","      <td>25-Sep-23</td>\n","      <td>3.963</td>\n","      <td>autumn</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1142 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf785b72-22d4-4daa-85ef-9034e353e427')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bf785b72-22d4-4daa-85ef-9034e353e427 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bf785b72-22d4-4daa-85ef-9034e353e427');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a33dba18-1ce3-4e24-9a88-844f63a4b466\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a33dba18-1ce3-4e24-9a88-844f63a4b466')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a33dba18-1ce3-4e24-9a88-844f63a4b466 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["season = {'spring': 0, 'summer': 1, 'autumn':2, 'winter': 3}\n","data_new.Season = [season[i] for i in data_new.Season]\n","data_new"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"LO9DB2y_Xx_H","executionInfo":{"status":"ok","timestamp":1702088415581,"user_tz":360,"elapsed":131,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"c882ba9c-5864-4a05-da54-5357b15f84d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Date for US Imports and Exports  \\\n","0                           9-Nov-01   \n","1                          16-Nov-01   \n","2                          23-Nov-01   \n","3                          30-Nov-01   \n","4                           7-Dec-01   \n","...                              ...   \n","1137                       25-Aug-23   \n","1138                        1-Sep-23   \n","1139                        8-Sep-23   \n","1140                       15-Sep-23   \n","1141                       22-Sep-23   \n","\n","      Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)  \\\n","0                                                 10772                                    \n","1                                                 10243                                    \n","2                                                  9576                                    \n","3                                                 11170                                    \n","4                                                  9885                                    \n","...                                                 ...                                    \n","1137                                              -1684                                    \n","1138                                              -2593                                    \n","1139                                                431                                    \n","1140                                              -2290                                    \n","1141                                              -1706                                    \n","\n","      Weekly U.S. Exports of Crude Oil (Thousand Barrels per Day)  \\\n","0                                                  9639             \n","1                                                  8879             \n","2                                                  8187             \n","3                                                  9856             \n","4                                                  8966             \n","...                                                 ...             \n","1137                                               2089             \n","1138                                               1838             \n","1139                                               4492             \n","1140                                               1450             \n","1141                                               3217             \n","\n","      Weekly U.S. Exports of Total Petroleum Products (Thousand Barrels per Day)  \\\n","0                                                  1133                            \n","1                                                  1364                            \n","2                                                  1389                            \n","3                                                  1314                            \n","4                                                   919                            \n","...                                                 ...                            \n","1137                                              -3773                            \n","1138                                              -4432                            \n","1139                                              -4061                            \n","1140                                              -3741                            \n","1141                                              -4923                            \n","\n","     Date for Retail Gas Price  \\\n","0                    12-Nov-01   \n","1                    19-Nov-01   \n","2                    26-Nov-01   \n","3                     3-Dec-01   \n","4                    10-Dec-01   \n","...                        ...   \n","1137                 28-Aug-23   \n","1138                  4-Sep-23   \n","1139                 11-Sep-23   \n","1140                 18-Sep-23   \n","1141                 25-Sep-23   \n","\n","      Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)  \\\n","0                                                 1.224                                     \n","1                                                 1.208                                     \n","2                                                 1.168                                     \n","3                                                 1.149                                     \n","4                                                 1.136                                     \n","...                                                 ...                                     \n","1137                                              3.931                                     \n","1138                                              3.925                                     \n","1139                                              3.941                                     \n","1140                                              4.001                                     \n","1141                                              3.963                                     \n","\n","      Season  \n","0          2  \n","1          2  \n","2          2  \n","3          2  \n","4          3  \n","...      ...  \n","1137       1  \n","1138       2  \n","1139       2  \n","1140       2  \n","1141       2  \n","\n","[1142 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-7cb31885-50b1-445a-8c25-9c5fc52e05fc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date for US Imports and Exports</th>\n","      <th>Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)</th>\n","      <th>Weekly U.S. Exports of Crude Oil (Thousand Barrels per Day)</th>\n","      <th>Weekly U.S. Exports of Total Petroleum Products (Thousand Barrels per Day)</th>\n","      <th>Date for Retail Gas Price</th>\n","      <th>Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)</th>\n","      <th>Season</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9-Nov-01</td>\n","      <td>10772</td>\n","      <td>9639</td>\n","      <td>1133</td>\n","      <td>12-Nov-01</td>\n","      <td>1.224</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>16-Nov-01</td>\n","      <td>10243</td>\n","      <td>8879</td>\n","      <td>1364</td>\n","      <td>19-Nov-01</td>\n","      <td>1.208</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23-Nov-01</td>\n","      <td>9576</td>\n","      <td>8187</td>\n","      <td>1389</td>\n","      <td>26-Nov-01</td>\n","      <td>1.168</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30-Nov-01</td>\n","      <td>11170</td>\n","      <td>9856</td>\n","      <td>1314</td>\n","      <td>3-Dec-01</td>\n","      <td>1.149</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7-Dec-01</td>\n","      <td>9885</td>\n","      <td>8966</td>\n","      <td>919</td>\n","      <td>10-Dec-01</td>\n","      <td>1.136</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1137</th>\n","      <td>25-Aug-23</td>\n","      <td>-1684</td>\n","      <td>2089</td>\n","      <td>-3773</td>\n","      <td>28-Aug-23</td>\n","      <td>3.931</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1138</th>\n","      <td>1-Sep-23</td>\n","      <td>-2593</td>\n","      <td>1838</td>\n","      <td>-4432</td>\n","      <td>4-Sep-23</td>\n","      <td>3.925</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1139</th>\n","      <td>8-Sep-23</td>\n","      <td>431</td>\n","      <td>4492</td>\n","      <td>-4061</td>\n","      <td>11-Sep-23</td>\n","      <td>3.941</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1140</th>\n","      <td>15-Sep-23</td>\n","      <td>-2290</td>\n","      <td>1450</td>\n","      <td>-3741</td>\n","      <td>18-Sep-23</td>\n","      <td>4.001</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1141</th>\n","      <td>22-Sep-23</td>\n","      <td>-1706</td>\n","      <td>3217</td>\n","      <td>-4923</td>\n","      <td>25-Sep-23</td>\n","      <td>3.963</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1142 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cb31885-50b1-445a-8c25-9c5fc52e05fc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7cb31885-50b1-445a-8c25-9c5fc52e05fc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7cb31885-50b1-445a-8c25-9c5fc52e05fc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-03eab344-6af7-458f-9481-aeae723733ac\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03eab344-6af7-458f-9481-aeae723733ac')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-03eab344-6af7-458f-9481-aeae723733ac button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["XY=data_new[['Date for US Imports and Exports','Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)','Season','Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)']].dropna(axis='index')\n","(feature1,featurename1)=('Date for US Imports and Exports',\"Year\")\n","(feature2,featurescale,featurename2)=('Weekly U.S. Exports of Crude Oil and Petroleum Products (Thousand Barrels per Day)',1000,\"Exports\")\n","(feature3,featurename3)=('Season','Season')\n","(label,labelname)=('Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)',\"Prices (Dollars per Gallon)\")\n","\n","\n","XY.columns=[featurename1,featurename2,featurename3,labelname]\n","XY[featurename1]=pandas.to_datetime(XY[featurename1]).dt.year\n","\n","print(XY)\n","\n","#X=XY[[featurename1,featurename2,featurename3]].squeeze()\n","#Y=XY[labelname].squeeze()\n","#print(X)\n","#print(Y)"],"metadata":{"id":"Xtw02SNgZ45f","executionInfo":{"status":"ok","timestamp":1702088482751,"user_tz":360,"elapsed":371,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"a0383a50-e487-4a68-94b3-428af7ea3b85","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      Year  Exports  Season  Prices (Dollars per Gallon)\n","0     2001    10772       2                        1.224\n","1     2001    10243       2                        1.208\n","2     2001     9576       2                        1.168\n","3     2001    11170       2                        1.149\n","4     2001     9885       3                        1.136\n","...    ...      ...     ...                          ...\n","1137  2023    -1684       1                        3.931\n","1138  2023    -2593       2                        3.925\n","1139  2023      431       2                        3.941\n","1140  2023    -2290       2                        4.001\n","1141  2023    -1706       2                        3.963\n","\n","[1142 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["#XY.to_csv('output_file.csv', index=False)\n","df_read = pandas.read_csv('output_file.csv')"],"metadata":{"id":"Ru9ebVMFYZ7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_read"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"zfYM5UBJZei9","executionInfo":{"status":"ok","timestamp":1702088798321,"user_tz":360,"elapsed":114,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"bd21f0ce-8d06-4465-8e33-b92bfc0c55f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Year  Exports  Season  Prices (Dollars per Gallon)\n","0     2001    10772       2                        1.224\n","1     2001    10243       2                        1.208\n","2     2001     9576       2                        1.168\n","3     2001    11170       2                        1.149\n","4     2001     9885       3                        1.136\n","...    ...      ...     ...                          ...\n","1137  2023    -1684       1                        3.931\n","1138  2023    -2593       2                        3.925\n","1139  2023      431       2                        3.941\n","1140  2023    -2290       2                        4.001\n","1141  2023    -1706       2                        3.963\n","\n","[1142 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-5fb5e5f6-078c-41aa-9c91-f4878f0050c1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Year</th>\n","      <th>Exports</th>\n","      <th>Season</th>\n","      <th>Prices (Dollars per Gallon)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2001</td>\n","      <td>10772</td>\n","      <td>2</td>\n","      <td>1.224</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2001</td>\n","      <td>10243</td>\n","      <td>2</td>\n","      <td>1.208</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2001</td>\n","      <td>9576</td>\n","      <td>2</td>\n","      <td>1.168</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2001</td>\n","      <td>11170</td>\n","      <td>2</td>\n","      <td>1.149</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2001</td>\n","      <td>9885</td>\n","      <td>3</td>\n","      <td>1.136</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1137</th>\n","      <td>2023</td>\n","      <td>-1684</td>\n","      <td>1</td>\n","      <td>3.931</td>\n","    </tr>\n","    <tr>\n","      <th>1138</th>\n","      <td>2023</td>\n","      <td>-2593</td>\n","      <td>2</td>\n","      <td>3.925</td>\n","    </tr>\n","    <tr>\n","      <th>1139</th>\n","      <td>2023</td>\n","      <td>431</td>\n","      <td>2</td>\n","      <td>3.941</td>\n","    </tr>\n","    <tr>\n","      <th>1140</th>\n","      <td>2023</td>\n","      <td>-2290</td>\n","      <td>2</td>\n","      <td>4.001</td>\n","    </tr>\n","    <tr>\n","      <th>1141</th>\n","      <td>2023</td>\n","      <td>-1706</td>\n","      <td>2</td>\n","      <td>3.963</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1142 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fb5e5f6-078c-41aa-9c91-f4878f0050c1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5fb5e5f6-078c-41aa-9c91-f4878f0050c1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5fb5e5f6-078c-41aa-9c91-f4878f0050c1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6b7c205e-5544-4865-8688-e516f0a7a14c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b7c205e-5544-4865-8688-e516f0a7a14c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6b7c205e-5544-4865-8688-e516f0a7a14c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["X = X.values\n","Y = Y.values"],"metadata":{"id":"po3Zj4I4QYf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data\n","x_train, x_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)    # change traning, testing, validating parameter\n","x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"],"metadata":{"id":"Gq3DuJGOXQF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n","\n","x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n","\n","x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"],"metadata":{"id":"2Hr92ehpcNOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for mini-batch training\n","class Build_Data(Dataset):\n","    def __init__(self,x,y):\n","        self.x = x\n","        self.y = y\n","        self.len = self.x.shape[0]\n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index]\n","    def __len__(self):\n","        return self.len\n","\n","dataset = Build_Data(x_train_tensor,y_train_tensor)"],"metadata":{"id":"T1GByXmUcR8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class pricePredictor_4layer(torch.nn.Module):\n","    def __init__(self,l1,l2,l3):\n","        super(pricePredictor_4layer, self).__init__()\n","        self.fc1 = torch.nn.Linear(3, l1)\n","        self.fc2 = torch.nn.Linear(l1, l2)\n","        self.fc3 = torch.nn.Linear(l2, l3)\n","        self.fc4 = torch.nn.Linear(l3, 1)\n","        #self.dropout=torch.nn.Dropout(p=0.2)\n","        #self.batchnorm1=torch.nn.BatchNorm1d(l1)\n","        #self.batchnorm2=torch.nn.BatchNorm1d(l2)\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        #x=self.batchnorm1(x)\n","        x=torch.relu(x)\n","        #x=self.dropout(x)\n","        x = self.fc2(x)\n","        #x=self.batchnorm2(x)\n","        x=torch.relu(x)\n","        #x=self.dropout(x)\n","        x = torch.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n"],"metadata":{"id":"wOtn3pbHuRfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main_model_training(param_m,lr_val,layer,batch_s,epoch,optimizer_select):\n","    model=None\n","    train_loader=None\n","    optimizer=None\n","    if layer==4:\n","      model=pricePredictor_4layer(param_m[0],param_m[1],param_m[2])\n","    #else:\n","     # model=pricePredictor_3layer(param_m[0],param_m[1])\n","    Loss = torch.nn.MSELoss()\n","\n","    #if batch_s==float('inf'):\n","      #train_loader = DataLoader(dataset=dataset)\n","    train_loader = DataLoader(dataset=dataset, batch_size=batch_s)\n","    if optimizer_select=='Adam':\n","      optimizer = torch.optim.Adam(model.parameters(), lr=lr_val)\n","    elif optimizer_select=='SGD':\n","      optimizer = torch.optim.SGD(model.parameters(), lr=lr_val)\n","    elif optimizer_select=='RMSprop':\n","      optimizer = torch.optim.RMSprop(model.parameters(), lr=lr_val)\n","\n","    train_losses = []\n","    val_losses = []\n","    device = \"cpu\"\n","    #if torch.cuda.is_available():\n","     #   device = \"cuda:0\"\n","    model.to(device)\n","    num_epochs = epoch\n","    for epoch in range(num_epochs):\n","      for x, y in train_loader:\n","        # Train\n","        #print('x',x)\n","        #print('y',y)\n","        model.train()\n","        optimizer.zero_grad()\n","        outputs = model(x)\n","        loss = Loss(outputs, y)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","\n","      # Validate\n","      model.eval()\n","      val_outputs = model(x_val_tensor)\n","      val_loss = Loss(val_outputs, y_val_tensor)\n","      val_losses.append(val_loss.item())\n","      if epoch % 10 == 0:\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n","    return model,train_losses,val_losses"],"metadata":{"id":"4Dj5bQt9DM7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model_layer(param_m,lr_val,layer,batch_s,epoch_num,optimizer_select):\n","    dict_param={}\n","    for i in range(len(param_m)):\n","        save_loss={}\n","        dict_loss={}\n","        for j in range(len(lr_val)):\n","            _,train_losses,val_losses=main_model_training(param_m[i],lr_val[j],layer,batch_s,epoch_num,optimizer_select)\n","            save_loss[j]=val_losses[-1]\n","        min_key = min(save_loss, key=save_loss.get)\n","        min_value = save_loss[min_key]\n","        dict_loss[min_key]=min_value\n","        dict_param[i]=dict_loss\n","    return dict_param"],"metadata":{"id":"raV_amKjtFUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The best model is\n","\n","best_param=[8,8,32] \\\n","best_no_layer=4 \\\n","with Adam optimizer\n"],"metadata":{"id":"_Bon8EIP-zuB"}},{"cell_type":"code","source":["best_param=[8,8,32]\n","best_lr=0.001\n","best_no_layer=4"],"metadata":{"id":"zVsuO4eBFJ0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_final,train_losses,val_losses=main_model_training(best_param,best_lr,best_no_layer,128,5000,'Adam')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weATMv-zRmNp","executionInfo":{"status":"ok","timestamp":1701924931790,"user_tz":360,"elapsed":109793,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"7b047ef2-d94c-47f3-af3f-60a190f41f5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5000, Training Loss: 71.1513900756836, Validation Loss: 50.70330810546875\n","Epoch 11/5000, Training Loss: 1.7456027269363403, Validation Loss: 0.7760196924209595\n","Epoch 21/5000, Training Loss: 1.3223077058792114, Validation Loss: 0.6683669090270996\n","Epoch 31/5000, Training Loss: 0.8942738175392151, Validation Loss: 0.5920575857162476\n","Epoch 41/5000, Training Loss: 0.5691721439361572, Validation Loss: 0.5463066697120667\n","Epoch 51/5000, Training Loss: 0.46237701177597046, Validation Loss: 0.4853442907333374\n","Epoch 61/5000, Training Loss: 0.45277851819992065, Validation Loss: 0.48017632961273193\n","Epoch 71/5000, Training Loss: 0.43852919340133667, Validation Loss: 0.479720801115036\n","Epoch 81/5000, Training Loss: 0.42125922441482544, Validation Loss: 0.48101794719696045\n","Epoch 91/5000, Training Loss: 0.40775617957115173, Validation Loss: 0.4814207851886749\n","Epoch 101/5000, Training Loss: 0.3987495005130768, Validation Loss: 0.4850156903266907\n","Epoch 111/5000, Training Loss: 0.3951099216938019, Validation Loss: 0.48445674777030945\n","Epoch 121/5000, Training Loss: 0.3918434977531433, Validation Loss: 0.4826107919216156\n","Epoch 131/5000, Training Loss: 0.39496976137161255, Validation Loss: 0.48331892490386963\n","Epoch 141/5000, Training Loss: 0.3936382830142975, Validation Loss: 0.4829983115196228\n","Epoch 151/5000, Training Loss: 0.3941946029663086, Validation Loss: 0.48213115334510803\n","Epoch 161/5000, Training Loss: 0.3975340723991394, Validation Loss: 0.48136433959007263\n","Epoch 171/5000, Training Loss: 0.3996371626853943, Validation Loss: 0.4801294505596161\n","Epoch 181/5000, Training Loss: 0.4003344178199768, Validation Loss: 0.4779691994190216\n","Epoch 191/5000, Training Loss: 0.3977924585342407, Validation Loss: 0.474834144115448\n","Epoch 201/5000, Training Loss: 0.3898600935935974, Validation Loss: 0.47900378704071045\n","Epoch 211/5000, Training Loss: 0.37214043736457825, Validation Loss: 0.49065595865249634\n","Epoch 221/5000, Training Loss: 0.3606014549732208, Validation Loss: 0.4959399104118347\n","Epoch 231/5000, Training Loss: 0.3528057932853699, Validation Loss: 0.49331244826316833\n","Epoch 241/5000, Training Loss: 0.35161933302879333, Validation Loss: 0.48580196499824524\n","Epoch 251/5000, Training Loss: 0.3507831394672394, Validation Loss: 0.48125484585762024\n","Epoch 261/5000, Training Loss: 0.35264310240745544, Validation Loss: 0.4762381315231323\n","Epoch 271/5000, Training Loss: 0.3543393611907959, Validation Loss: 0.47188737988471985\n","Epoch 281/5000, Training Loss: 0.3554534912109375, Validation Loss: 0.4701370298862457\n","Epoch 291/5000, Training Loss: 0.3547779619693756, Validation Loss: 0.46855035424232483\n","Epoch 301/5000, Training Loss: 0.3622453212738037, Validation Loss: 0.46223703026771545\n","Epoch 311/5000, Training Loss: 0.3583671748638153, Validation Loss: 0.4653807580471039\n","Epoch 321/5000, Training Loss: 0.3554702401161194, Validation Loss: 0.4629683494567871\n","Epoch 331/5000, Training Loss: 0.3653683066368103, Validation Loss: 0.4595091640949249\n","Epoch 341/5000, Training Loss: 0.3635944426059723, Validation Loss: 0.4618750810623169\n","Epoch 351/5000, Training Loss: 0.36355334520339966, Validation Loss: 0.4585880935192108\n","Epoch 361/5000, Training Loss: 0.3644627034664154, Validation Loss: 0.45740842819213867\n","Epoch 371/5000, Training Loss: 0.3650132715702057, Validation Loss: 0.458482027053833\n","Epoch 381/5000, Training Loss: 0.3696252107620239, Validation Loss: 0.45816200971603394\n","Epoch 391/5000, Training Loss: 0.37144118547439575, Validation Loss: 0.459519624710083\n","Epoch 401/5000, Training Loss: 0.3715098798274994, Validation Loss: 0.4613584876060486\n","Epoch 411/5000, Training Loss: 0.370695024728775, Validation Loss: 0.4572705626487732\n","Epoch 421/5000, Training Loss: 0.3751963973045349, Validation Loss: 0.45664167404174805\n","Epoch 431/5000, Training Loss: 0.37102243304252625, Validation Loss: 0.459461510181427\n","Epoch 441/5000, Training Loss: 0.37528130412101746, Validation Loss: 0.4583738148212433\n","Epoch 451/5000, Training Loss: 0.37279343605041504, Validation Loss: 0.4597913920879364\n","Epoch 461/5000, Training Loss: 0.3753727972507477, Validation Loss: 0.45559990406036377\n","Epoch 471/5000, Training Loss: 0.37536442279815674, Validation Loss: 0.4586044251918793\n","Epoch 481/5000, Training Loss: 0.37648341059684753, Validation Loss: 0.45751988887786865\n","Epoch 491/5000, Training Loss: 0.3725041449069977, Validation Loss: 0.45637646317481995\n","Epoch 501/5000, Training Loss: 0.3734720051288605, Validation Loss: 0.4599376618862152\n","Epoch 511/5000, Training Loss: 0.3732689619064331, Validation Loss: 0.4575408697128296\n","Epoch 521/5000, Training Loss: 0.3746907711029053, Validation Loss: 0.4577574133872986\n","Epoch 531/5000, Training Loss: 0.3751729428768158, Validation Loss: 0.4544999301433563\n","Epoch 541/5000, Training Loss: 0.3732088506221771, Validation Loss: 0.45485445857048035\n","Epoch 551/5000, Training Loss: 0.37337639927864075, Validation Loss: 0.460978627204895\n","Epoch 561/5000, Training Loss: 0.37010300159454346, Validation Loss: 0.45696887373924255\n","Epoch 571/5000, Training Loss: 0.3712465763092041, Validation Loss: 0.45820340514183044\n","Epoch 581/5000, Training Loss: 0.37718191742897034, Validation Loss: 0.45550528168678284\n","Epoch 591/5000, Training Loss: 0.37545889616012573, Validation Loss: 0.4637449383735657\n","Epoch 601/5000, Training Loss: 0.3811068832874298, Validation Loss: 0.4659978449344635\n","Epoch 611/5000, Training Loss: 0.3785912096500397, Validation Loss: 0.4588956832885742\n","Epoch 621/5000, Training Loss: 0.38249343633651733, Validation Loss: 0.4668765664100647\n","Epoch 631/5000, Training Loss: 0.37556761503219604, Validation Loss: 0.4616446793079376\n","Epoch 641/5000, Training Loss: 0.3816990256309509, Validation Loss: 0.46171247959136963\n","Epoch 651/5000, Training Loss: 0.3742983341217041, Validation Loss: 0.46537289023399353\n","Epoch 661/5000, Training Loss: 0.38044273853302, Validation Loss: 0.46438542008399963\n","Epoch 671/5000, Training Loss: 0.37668508291244507, Validation Loss: 0.46290409564971924\n","Epoch 681/5000, Training Loss: 0.38019803166389465, Validation Loss: 0.4619290232658386\n","Epoch 691/5000, Training Loss: 0.3734290897846222, Validation Loss: 0.45920366048812866\n","Epoch 701/5000, Training Loss: 0.3740840554237366, Validation Loss: 0.45774412155151367\n","Epoch 711/5000, Training Loss: 0.37874582409858704, Validation Loss: 0.45435631275177\n","Epoch 721/5000, Training Loss: 0.3902142345905304, Validation Loss: 0.4607264995574951\n","Epoch 731/5000, Training Loss: 0.36242976784706116, Validation Loss: 0.44490501284599304\n","Epoch 741/5000, Training Loss: 0.3766876459121704, Validation Loss: 0.4604821503162384\n","Epoch 751/5000, Training Loss: 0.3737033009529114, Validation Loss: 0.45265161991119385\n","Epoch 761/5000, Training Loss: 0.3745590150356293, Validation Loss: 0.46255064010620117\n","Epoch 771/5000, Training Loss: 0.3744065761566162, Validation Loss: 0.4596156179904938\n","Epoch 781/5000, Training Loss: 0.3816421627998352, Validation Loss: 0.451749712228775\n","Epoch 791/5000, Training Loss: 0.3704839050769806, Validation Loss: 0.4474814236164093\n","Epoch 801/5000, Training Loss: 0.37416741251945496, Validation Loss: 0.4484733045101166\n","Epoch 811/5000, Training Loss: 0.37397700548171997, Validation Loss: 0.45518577098846436\n","Epoch 821/5000, Training Loss: 0.37020665407180786, Validation Loss: 0.4486209750175476\n","Epoch 831/5000, Training Loss: 0.372081995010376, Validation Loss: 0.45035478472709656\n","Epoch 841/5000, Training Loss: 0.376592218875885, Validation Loss: 0.45817142724990845\n","Epoch 851/5000, Training Loss: 0.37582823634147644, Validation Loss: 0.4515528976917267\n","Epoch 861/5000, Training Loss: 0.36798641085624695, Validation Loss: 0.4436572194099426\n","Epoch 871/5000, Training Loss: 0.3663471043109894, Validation Loss: 0.4439901113510132\n","Epoch 881/5000, Training Loss: 0.37671908736228943, Validation Loss: 0.4498266875743866\n","Epoch 891/5000, Training Loss: 0.36902621388435364, Validation Loss: 0.4485839605331421\n","Epoch 901/5000, Training Loss: 0.37472987174987793, Validation Loss: 0.4490726888179779\n","Epoch 911/5000, Training Loss: 0.36617958545684814, Validation Loss: 0.4379498362541199\n","Epoch 921/5000, Training Loss: 0.35961323976516724, Validation Loss: 0.44841596484184265\n","Epoch 931/5000, Training Loss: 0.38002100586891174, Validation Loss: 0.4554741084575653\n","Epoch 941/5000, Training Loss: 0.3659173846244812, Validation Loss: 0.4460873007774353\n","Epoch 951/5000, Training Loss: 0.3635132610797882, Validation Loss: 0.45760074257850647\n","Epoch 961/5000, Training Loss: 0.3669927418231964, Validation Loss: 0.44644811749458313\n","Epoch 971/5000, Training Loss: 0.36679607629776, Validation Loss: 0.44596096873283386\n","Epoch 981/5000, Training Loss: 0.3703405261039734, Validation Loss: 0.4503864347934723\n","Epoch 991/5000, Training Loss: 0.36562660336494446, Validation Loss: 0.44066599011421204\n","Epoch 1001/5000, Training Loss: 0.3643796443939209, Validation Loss: 0.4448452889919281\n","Epoch 1011/5000, Training Loss: 0.371023029088974, Validation Loss: 0.44324764609336853\n","Epoch 1021/5000, Training Loss: 0.3664526641368866, Validation Loss: 0.43886053562164307\n","Epoch 1031/5000, Training Loss: 0.37491658329963684, Validation Loss: 0.4353458881378174\n","Epoch 1041/5000, Training Loss: 0.3642873167991638, Validation Loss: 0.4374399781227112\n","Epoch 1051/5000, Training Loss: 0.3682142496109009, Validation Loss: 0.43915000557899475\n","Epoch 1061/5000, Training Loss: 0.36511895060539246, Validation Loss: 0.4410332441329956\n","Epoch 1071/5000, Training Loss: 0.36387085914611816, Validation Loss: 0.44139564037323\n","Epoch 1081/5000, Training Loss: 0.3639121651649475, Validation Loss: 0.4431542158126831\n","Epoch 1091/5000, Training Loss: 0.3773389756679535, Validation Loss: 0.43603554368019104\n","Epoch 1101/5000, Training Loss: 0.36949270963668823, Validation Loss: 0.4356735050678253\n","Epoch 1111/5000, Training Loss: 0.3736514747142792, Validation Loss: 0.4537979066371918\n","Epoch 1121/5000, Training Loss: 0.3683672249317169, Validation Loss: 0.43861135840415955\n","Epoch 1131/5000, Training Loss: 0.3664970397949219, Validation Loss: 0.4364538788795471\n","Epoch 1141/5000, Training Loss: 0.36340364813804626, Validation Loss: 0.4376927316188812\n","Epoch 1151/5000, Training Loss: 0.37014102935791016, Validation Loss: 0.4255858361721039\n","Epoch 1161/5000, Training Loss: 0.36559706926345825, Validation Loss: 0.43639203906059265\n","Epoch 1171/5000, Training Loss: 0.369206964969635, Validation Loss: 0.429858922958374\n","Epoch 1181/5000, Training Loss: 0.37312448024749756, Validation Loss: 0.435014009475708\n","Epoch 1191/5000, Training Loss: 0.37593206763267517, Validation Loss: 0.4357464015483856\n","Epoch 1201/5000, Training Loss: 0.37340718507766724, Validation Loss: 0.4347764253616333\n","Epoch 1211/5000, Training Loss: 0.37874454259872437, Validation Loss: 0.44348621368408203\n","Epoch 1221/5000, Training Loss: 0.36719292402267456, Validation Loss: 0.42845475673675537\n","Epoch 1231/5000, Training Loss: 0.3815827965736389, Validation Loss: 0.4437228739261627\n","Epoch 1241/5000, Training Loss: 0.3616994023323059, Validation Loss: 0.4350886642932892\n","Epoch 1251/5000, Training Loss: 0.3629903495311737, Validation Loss: 0.43485966324806213\n","Epoch 1261/5000, Training Loss: 0.37382832169532776, Validation Loss: 0.42782512307167053\n","Epoch 1271/5000, Training Loss: 0.36699244379997253, Validation Loss: 0.42541739344596863\n","Epoch 1281/5000, Training Loss: 0.3646843135356903, Validation Loss: 0.42906707525253296\n","Epoch 1291/5000, Training Loss: 0.36182987689971924, Validation Loss: 0.43017539381980896\n","Epoch 1301/5000, Training Loss: 0.3544594943523407, Validation Loss: 0.42921850085258484\n","Epoch 1311/5000, Training Loss: 0.3839358687400818, Validation Loss: 0.43978336453437805\n","Epoch 1321/5000, Training Loss: 0.359485924243927, Validation Loss: 0.4311978220939636\n","Epoch 1331/5000, Training Loss: 0.35953488945961, Validation Loss: 0.4326954483985901\n","Epoch 1341/5000, Training Loss: 0.3701370358467102, Validation Loss: 0.42701461911201477\n","Epoch 1351/5000, Training Loss: 0.3595517873764038, Validation Loss: 0.42762288451194763\n","Epoch 1361/5000, Training Loss: 0.36102333664894104, Validation Loss: 0.42584604024887085\n","Epoch 1371/5000, Training Loss: 0.37467291951179504, Validation Loss: 0.43142664432525635\n","Epoch 1381/5000, Training Loss: 0.36262786388397217, Validation Loss: 0.4277684688568115\n","Epoch 1391/5000, Training Loss: 0.37245097756385803, Validation Loss: 0.438598096370697\n","Epoch 1401/5000, Training Loss: 0.36545634269714355, Validation Loss: 0.425810843706131\n","Epoch 1411/5000, Training Loss: 0.3717971742153168, Validation Loss: 0.43670907616615295\n","Epoch 1421/5000, Training Loss: 0.35679805278778076, Validation Loss: 0.430740088224411\n","Epoch 1431/5000, Training Loss: 0.36566224694252014, Validation Loss: 0.42318761348724365\n","Epoch 1441/5000, Training Loss: 0.3575988709926605, Validation Loss: 0.4214852452278137\n","Epoch 1451/5000, Training Loss: 0.35901620984077454, Validation Loss: 0.42138153314590454\n","Epoch 1461/5000, Training Loss: 0.3689376711845398, Validation Loss: 0.4331379532814026\n","Epoch 1471/5000, Training Loss: 0.3559214472770691, Validation Loss: 0.42601922154426575\n","Epoch 1481/5000, Training Loss: 0.36158591508865356, Validation Loss: 0.41841715574264526\n","Epoch 1491/5000, Training Loss: 0.35792410373687744, Validation Loss: 0.42307227849960327\n","Epoch 1501/5000, Training Loss: 0.3642285168170929, Validation Loss: 0.42140236496925354\n","Epoch 1511/5000, Training Loss: 0.3815629780292511, Validation Loss: 0.4283211827278137\n","Epoch 1521/5000, Training Loss: 0.37077829241752625, Validation Loss: 0.41918283700942993\n","Epoch 1531/5000, Training Loss: 0.3640245497226715, Validation Loss: 0.41928917169570923\n","Epoch 1541/5000, Training Loss: 0.3729621469974518, Validation Loss: 0.4210508167743683\n","Epoch 1551/5000, Training Loss: 0.36671939492225647, Validation Loss: 0.41299572587013245\n","Epoch 1561/5000, Training Loss: 0.3611484467983246, Validation Loss: 0.41673070192337036\n","Epoch 1571/5000, Training Loss: 0.36162981390953064, Validation Loss: 0.41150590777397156\n","Epoch 1581/5000, Training Loss: 0.3707350194454193, Validation Loss: 0.4166160225868225\n","Epoch 1591/5000, Training Loss: 0.36161476373672485, Validation Loss: 0.4122028946876526\n","Epoch 1601/5000, Training Loss: 0.37091803550720215, Validation Loss: 0.413616418838501\n","Epoch 1611/5000, Training Loss: 0.3710332214832306, Validation Loss: 0.4090490937232971\n","Epoch 1621/5000, Training Loss: 0.360545814037323, Validation Loss: 0.41087931394577026\n","Epoch 1631/5000, Training Loss: 0.3595820367336273, Validation Loss: 0.40971440076828003\n","Epoch 1641/5000, Training Loss: 0.3691435754299164, Validation Loss: 0.4034425616264343\n","Epoch 1651/5000, Training Loss: 0.3490300476551056, Validation Loss: 0.40775981545448303\n","Epoch 1661/5000, Training Loss: 0.3605508804321289, Validation Loss: 0.4041177034378052\n","Epoch 1671/5000, Training Loss: 0.35052573680877686, Validation Loss: 0.40436920523643494\n","Epoch 1681/5000, Training Loss: 0.3734603822231293, Validation Loss: 0.4015812575817108\n","Epoch 1691/5000, Training Loss: 0.3534681797027588, Validation Loss: 0.397863507270813\n","Epoch 1701/5000, Training Loss: 0.45425349473953247, Validation Loss: 0.4607563614845276\n","Epoch 1711/5000, Training Loss: 0.37520739436149597, Validation Loss: 0.4182867407798767\n","Epoch 1721/5000, Training Loss: 0.36518779397010803, Validation Loss: 0.391200453042984\n","Epoch 1731/5000, Training Loss: 0.32789021730422974, Validation Loss: 0.3838728070259094\n","Epoch 1741/5000, Training Loss: 0.3941190540790558, Validation Loss: 0.42802804708480835\n","Epoch 1751/5000, Training Loss: 0.41231420636177063, Validation Loss: 0.4348719120025635\n","Epoch 1761/5000, Training Loss: 0.3757968544960022, Validation Loss: 0.424759179353714\n","Epoch 1771/5000, Training Loss: 0.404148668050766, Validation Loss: 0.44339224696159363\n","Epoch 1781/5000, Training Loss: 0.37545105814933777, Validation Loss: 0.3927772045135498\n","Epoch 1791/5000, Training Loss: 0.3522980511188507, Validation Loss: 0.40137574076652527\n","Epoch 1801/5000, Training Loss: 0.3852548897266388, Validation Loss: 0.45846667885780334\n","Epoch 1811/5000, Training Loss: 0.3572942018508911, Validation Loss: 0.4274176061153412\n","Epoch 1821/5000, Training Loss: 0.37652185559272766, Validation Loss: 0.4022827446460724\n","Epoch 1831/5000, Training Loss: 0.36530449986457825, Validation Loss: 0.4239045977592468\n","Epoch 1841/5000, Training Loss: 0.38754206895828247, Validation Loss: 0.398055762052536\n","Epoch 1851/5000, Training Loss: 0.3639005124568939, Validation Loss: 0.40413424372673035\n","Epoch 1861/5000, Training Loss: 0.37043070793151855, Validation Loss: 0.4169340431690216\n","Epoch 1871/5000, Training Loss: 0.3959083557128906, Validation Loss: 0.40564656257629395\n","Epoch 1881/5000, Training Loss: 0.37969306111335754, Validation Loss: 0.4334726929664612\n","Epoch 1891/5000, Training Loss: 0.363856703042984, Validation Loss: 0.42462679743766785\n","Epoch 1901/5000, Training Loss: 0.3439961075782776, Validation Loss: 0.3870866894721985\n","Epoch 1911/5000, Training Loss: 0.3528881371021271, Validation Loss: 0.4050368070602417\n","Epoch 1921/5000, Training Loss: 0.3293909430503845, Validation Loss: 0.3802115321159363\n","Epoch 1931/5000, Training Loss: 0.34955352544784546, Validation Loss: 0.4424925148487091\n","Epoch 1941/5000, Training Loss: 0.3243456184864044, Validation Loss: 0.41976451873779297\n","Epoch 1951/5000, Training Loss: 0.3534855246543884, Validation Loss: 0.4084990322589874\n","Epoch 1961/5000, Training Loss: 0.3717595934867859, Validation Loss: 0.40933191776275635\n","Epoch 1971/5000, Training Loss: 0.36472049355506897, Validation Loss: 0.4250389337539673\n","Epoch 1981/5000, Training Loss: 0.32802441716194153, Validation Loss: 0.3908725678920746\n","Epoch 1991/5000, Training Loss: 0.3424256443977356, Validation Loss: 0.3948826491832733\n","Epoch 2001/5000, Training Loss: 0.36923277378082275, Validation Loss: 0.4004439115524292\n","Epoch 2011/5000, Training Loss: 0.37614497542381287, Validation Loss: 0.3949125111103058\n","Epoch 2021/5000, Training Loss: 0.35061195492744446, Validation Loss: 0.4060475826263428\n","Epoch 2031/5000, Training Loss: 0.33592864871025085, Validation Loss: 0.4002351760864258\n","Epoch 2041/5000, Training Loss: 0.3255268931388855, Validation Loss: 0.40615639090538025\n","Epoch 2051/5000, Training Loss: 0.3552528917789459, Validation Loss: 0.42407292127609253\n","Epoch 2061/5000, Training Loss: 0.3596973717212677, Validation Loss: 0.41165170073509216\n","Epoch 2071/5000, Training Loss: 0.3626977801322937, Validation Loss: 0.4221886396408081\n","Epoch 2081/5000, Training Loss: 0.385208398103714, Validation Loss: 0.3930806815624237\n","Epoch 2091/5000, Training Loss: 0.35478147864341736, Validation Loss: 0.39597463607788086\n","Epoch 2101/5000, Training Loss: 0.35550397634506226, Validation Loss: 0.42361897230148315\n","Epoch 2111/5000, Training Loss: 0.3972856104373932, Validation Loss: 0.41481146216392517\n","Epoch 2121/5000, Training Loss: 0.3686576783657074, Validation Loss: 0.3915245234966278\n","Epoch 2131/5000, Training Loss: 0.33450159430503845, Validation Loss: 0.38750267028808594\n","Epoch 2141/5000, Training Loss: 0.31025612354278564, Validation Loss: 0.3763394355773926\n","Epoch 2151/5000, Training Loss: 0.38177400827407837, Validation Loss: 0.42238160967826843\n","Epoch 2161/5000, Training Loss: 0.38676661252975464, Validation Loss: 0.44661712646484375\n","Epoch 2171/5000, Training Loss: 0.35016095638275146, Validation Loss: 0.39120638370513916\n","Epoch 2181/5000, Training Loss: 0.3157252073287964, Validation Loss: 0.3827555775642395\n","Epoch 2191/5000, Training Loss: 0.32704225182533264, Validation Loss: 0.3972187936306\n","Epoch 2201/5000, Training Loss: 0.32807794213294983, Validation Loss: 0.4187939763069153\n","Epoch 2211/5000, Training Loss: 0.3222413659095764, Validation Loss: 0.38548171520233154\n","Epoch 2221/5000, Training Loss: 0.3596305847167969, Validation Loss: 0.4054053723812103\n","Epoch 2231/5000, Training Loss: 0.32417285442352295, Validation Loss: 0.3834654986858368\n","Epoch 2241/5000, Training Loss: 0.40103891491889954, Validation Loss: 0.39521750807762146\n","Epoch 2251/5000, Training Loss: 0.3399595320224762, Validation Loss: 0.4152884781360626\n","Epoch 2261/5000, Training Loss: 0.33033737540245056, Validation Loss: 0.40011751651763916\n","Epoch 2271/5000, Training Loss: 0.3188343048095703, Validation Loss: 0.3925500214099884\n","Epoch 2281/5000, Training Loss: 0.3292819559574127, Validation Loss: 0.39344659447669983\n","Epoch 2291/5000, Training Loss: 0.37024661898612976, Validation Loss: 0.41571834683418274\n","Epoch 2301/5000, Training Loss: 0.3610876798629761, Validation Loss: 0.4416654706001282\n","Epoch 2311/5000, Training Loss: 0.36063459515571594, Validation Loss: 0.3995203375816345\n","Epoch 2321/5000, Training Loss: 0.31910789012908936, Validation Loss: 0.38871467113494873\n","Epoch 2331/5000, Training Loss: 0.329447865486145, Validation Loss: 0.41767066717147827\n","Epoch 2341/5000, Training Loss: 0.36265823245048523, Validation Loss: 0.4216518700122833\n","Epoch 2351/5000, Training Loss: 0.3540401756763458, Validation Loss: 0.41559597849845886\n","Epoch 2361/5000, Training Loss: 0.3270243704319, Validation Loss: 0.42574936151504517\n","Epoch 2371/5000, Training Loss: 0.3445395231246948, Validation Loss: 0.4053373336791992\n","Epoch 2381/5000, Training Loss: 0.35060733556747437, Validation Loss: 0.42206037044525146\n","Epoch 2391/5000, Training Loss: 0.33312758803367615, Validation Loss: 0.4296274781227112\n","Epoch 2401/5000, Training Loss: 0.3266622722148895, Validation Loss: 0.4062562584877014\n","Epoch 2411/5000, Training Loss: 0.3772004246711731, Validation Loss: 0.4314715266227722\n","Epoch 2421/5000, Training Loss: 0.33986011147499084, Validation Loss: 0.41022923588752747\n","Epoch 2431/5000, Training Loss: 0.33449289202690125, Validation Loss: 0.4087786376476288\n","Epoch 2441/5000, Training Loss: 0.3040628433227539, Validation Loss: 0.4087585508823395\n","Epoch 2451/5000, Training Loss: 0.3362480103969574, Validation Loss: 0.4236689805984497\n","Epoch 2461/5000, Training Loss: 0.32197844982147217, Validation Loss: 0.40408825874328613\n","Epoch 2471/5000, Training Loss: 0.3139655292034149, Validation Loss: 0.4056369662284851\n","Epoch 2481/5000, Training Loss: 0.33911195397377014, Validation Loss: 0.43640974164009094\n","Epoch 2491/5000, Training Loss: 0.36689963936805725, Validation Loss: 0.3953748941421509\n","Epoch 2501/5000, Training Loss: 0.409983366727829, Validation Loss: 0.44813787937164307\n","Epoch 2511/5000, Training Loss: 0.320226788520813, Validation Loss: 0.3851514756679535\n","Epoch 2521/5000, Training Loss: 0.33598968386650085, Validation Loss: 0.4126628041267395\n","Epoch 2531/5000, Training Loss: 0.3224879801273346, Validation Loss: 0.40897801518440247\n","Epoch 2541/5000, Training Loss: 0.3959681987762451, Validation Loss: 0.4147736728191376\n","Epoch 2551/5000, Training Loss: 0.32128605246543884, Validation Loss: 0.40805914998054504\n","Epoch 2561/5000, Training Loss: 0.40071049332618713, Validation Loss: 0.42697322368621826\n","Epoch 2571/5000, Training Loss: 0.33172059059143066, Validation Loss: 0.4146387577056885\n","Epoch 2581/5000, Training Loss: 0.3271339237689972, Validation Loss: 0.4064520597457886\n","Epoch 2591/5000, Training Loss: 0.31390175223350525, Validation Loss: 0.4139329195022583\n","Epoch 2601/5000, Training Loss: 0.32379838824272156, Validation Loss: 0.42478814721107483\n","Epoch 2611/5000, Training Loss: 0.37644678354263306, Validation Loss: 0.40021562576293945\n","Epoch 2621/5000, Training Loss: 0.3196372389793396, Validation Loss: 0.4193352162837982\n","Epoch 2631/5000, Training Loss: 0.3941819965839386, Validation Loss: 0.4232952296733856\n","Epoch 2641/5000, Training Loss: 0.31262409687042236, Validation Loss: 0.4156208634376526\n","Epoch 2651/5000, Training Loss: 0.3269766569137573, Validation Loss: 0.4120291471481323\n","Epoch 2661/5000, Training Loss: 0.3373163938522339, Validation Loss: 0.41763800382614136\n","Epoch 2671/5000, Training Loss: 0.3088279366493225, Validation Loss: 0.3893425464630127\n","Epoch 2681/5000, Training Loss: 0.3092631697654724, Validation Loss: 0.40450817346572876\n","Epoch 2691/5000, Training Loss: 0.32698050141334534, Validation Loss: 0.4460090100765228\n","Epoch 2701/5000, Training Loss: 0.34810277819633484, Validation Loss: 0.4269550144672394\n","Epoch 2711/5000, Training Loss: 0.3678078353404999, Validation Loss: 0.39938297867774963\n","Epoch 2721/5000, Training Loss: 0.3828798234462738, Validation Loss: 0.40519285202026367\n","Epoch 2731/5000, Training Loss: 0.3203650414943695, Validation Loss: 0.3946641683578491\n","Epoch 2741/5000, Training Loss: 0.32323282957077026, Validation Loss: 0.4209938645362854\n","Epoch 2751/5000, Training Loss: 0.33043381571769714, Validation Loss: 0.42707476019859314\n","Epoch 2761/5000, Training Loss: 0.30661913752555847, Validation Loss: 0.3875954747200012\n","Epoch 2771/5000, Training Loss: 0.3612425923347473, Validation Loss: 0.40514039993286133\n","Epoch 2781/5000, Training Loss: 0.3376444876194, Validation Loss: 0.4158487915992737\n","Epoch 2791/5000, Training Loss: 0.30978742241859436, Validation Loss: 0.3899161219596863\n","Epoch 2801/5000, Training Loss: 0.35436609387397766, Validation Loss: 0.41090840101242065\n","Epoch 2811/5000, Training Loss: 0.3260731101036072, Validation Loss: 0.4435109496116638\n","Epoch 2821/5000, Training Loss: 0.31428107619285583, Validation Loss: 0.4138765335083008\n","Epoch 2831/5000, Training Loss: 0.3223985731601715, Validation Loss: 0.404413104057312\n","Epoch 2841/5000, Training Loss: 0.3150462508201599, Validation Loss: 0.40358778834342957\n","Epoch 2851/5000, Training Loss: 0.33817926049232483, Validation Loss: 0.39025601744651794\n","Epoch 2861/5000, Training Loss: 0.31481868028640747, Validation Loss: 0.38889628648757935\n","Epoch 2871/5000, Training Loss: 0.3167959153652191, Validation Loss: 0.4048978090286255\n","Epoch 2881/5000, Training Loss: 0.3080334961414337, Validation Loss: 0.3887854218482971\n","Epoch 2891/5000, Training Loss: 0.31065085530281067, Validation Loss: 0.40470561385154724\n","Epoch 2901/5000, Training Loss: 0.3062841296195984, Validation Loss: 0.4064894914627075\n","Epoch 2911/5000, Training Loss: 0.3124498426914215, Validation Loss: 0.39909201860427856\n","Epoch 2921/5000, Training Loss: 0.31087014079093933, Validation Loss: 0.3847757875919342\n","Epoch 2931/5000, Training Loss: 0.31288713216781616, Validation Loss: 0.3946658670902252\n","Epoch 2941/5000, Training Loss: 0.3089155852794647, Validation Loss: 0.39865347743034363\n","Epoch 2951/5000, Training Loss: 0.3083035349845886, Validation Loss: 0.4036206603050232\n","Epoch 2961/5000, Training Loss: 0.3029220402240753, Validation Loss: 0.3905712068080902\n","Epoch 2971/5000, Training Loss: 0.31657496094703674, Validation Loss: 0.40219128131866455\n","Epoch 2981/5000, Training Loss: 0.3222561180591583, Validation Loss: 0.4139472246170044\n","Epoch 2991/5000, Training Loss: 0.33038273453712463, Validation Loss: 0.4402903616428375\n","Epoch 3001/5000, Training Loss: 0.320132851600647, Validation Loss: 0.42739906907081604\n","Epoch 3011/5000, Training Loss: 0.32180875539779663, Validation Loss: 0.4375889301300049\n","Epoch 3021/5000, Training Loss: 0.40590617060661316, Validation Loss: 0.4247280955314636\n","Epoch 3031/5000, Training Loss: 0.2942343056201935, Validation Loss: 0.3825282156467438\n","Epoch 3041/5000, Training Loss: 0.32885274291038513, Validation Loss: 0.3931344449520111\n","Epoch 3051/5000, Training Loss: 0.33409056067466736, Validation Loss: 0.3857843577861786\n","Epoch 3061/5000, Training Loss: 0.3269531726837158, Validation Loss: 0.40616363286972046\n","Epoch 3071/5000, Training Loss: 0.3244594931602478, Validation Loss: 0.4218864142894745\n","Epoch 3081/5000, Training Loss: 0.3034912645816803, Validation Loss: 0.38708585500717163\n","Epoch 3091/5000, Training Loss: 0.3343697190284729, Validation Loss: 0.3959348499774933\n","Epoch 3101/5000, Training Loss: 0.30862101912498474, Validation Loss: 0.4038871228694916\n","Epoch 3111/5000, Training Loss: 0.2957351803779602, Validation Loss: 0.393198162317276\n","Epoch 3121/5000, Training Loss: 0.31683847308158875, Validation Loss: 0.3924509584903717\n","Epoch 3131/5000, Training Loss: 0.34081053733825684, Validation Loss: 0.4230586290359497\n","Epoch 3141/5000, Training Loss: 0.333841472864151, Validation Loss: 0.40502941608428955\n","Epoch 3151/5000, Training Loss: 0.32844722270965576, Validation Loss: 0.39401182532310486\n","Epoch 3161/5000, Training Loss: 0.36347857117652893, Validation Loss: 0.4476328492164612\n","Epoch 3171/5000, Training Loss: 0.42214152216911316, Validation Loss: 0.4255818724632263\n","Epoch 3181/5000, Training Loss: 0.30610138177871704, Validation Loss: 0.42086803913116455\n","Epoch 3191/5000, Training Loss: 0.30778899788856506, Validation Loss: 0.38351622223854065\n","Epoch 3201/5000, Training Loss: 0.34806355834007263, Validation Loss: 0.39984527230262756\n","Epoch 3211/5000, Training Loss: 0.33484572172164917, Validation Loss: 0.43760737776756287\n","Epoch 3221/5000, Training Loss: 0.2989725172519684, Validation Loss: 0.38711774349212646\n","Epoch 3231/5000, Training Loss: 0.36397480964660645, Validation Loss: 0.41734448075294495\n","Epoch 3241/5000, Training Loss: 0.3161356449127197, Validation Loss: 0.4179145395755768\n","Epoch 3251/5000, Training Loss: 0.29284822940826416, Validation Loss: 0.385355144739151\n","Epoch 3261/5000, Training Loss: 0.3027140498161316, Validation Loss: 0.4051882326602936\n","Epoch 3271/5000, Training Loss: 0.32138654589653015, Validation Loss: 0.4056975543498993\n","Epoch 3281/5000, Training Loss: 0.30204859375953674, Validation Loss: 0.4015570282936096\n","Epoch 3291/5000, Training Loss: 0.3402353823184967, Validation Loss: 0.40576881170272827\n","Epoch 3301/5000, Training Loss: 0.2947009801864624, Validation Loss: 0.3819350004196167\n","Epoch 3311/5000, Training Loss: 0.31500837206840515, Validation Loss: 0.38703423738479614\n","Epoch 3321/5000, Training Loss: 0.30972832441329956, Validation Loss: 0.3821520507335663\n","Epoch 3331/5000, Training Loss: 0.3618800938129425, Validation Loss: 0.4310985505580902\n","Epoch 3341/5000, Training Loss: 0.33443954586982727, Validation Loss: 0.42830750346183777\n","Epoch 3351/5000, Training Loss: 0.3694396913051605, Validation Loss: 0.3944062888622284\n","Epoch 3361/5000, Training Loss: 0.3322724401950836, Validation Loss: 0.4190284013748169\n","Epoch 3371/5000, Training Loss: 0.352568656206131, Validation Loss: 0.3946358263492584\n","Epoch 3381/5000, Training Loss: 0.344568133354187, Validation Loss: 0.42479848861694336\n","Epoch 3391/5000, Training Loss: 0.31146472692489624, Validation Loss: 0.42415979504585266\n","Epoch 3401/5000, Training Loss: 0.3077240586280823, Validation Loss: 0.40396782755851746\n","Epoch 3411/5000, Training Loss: 0.3167939782142639, Validation Loss: 0.4024709165096283\n","Epoch 3421/5000, Training Loss: 0.3078800439834595, Validation Loss: 0.40352439880371094\n","Epoch 3431/5000, Training Loss: 0.3435385227203369, Validation Loss: 0.41030701994895935\n","Epoch 3441/5000, Training Loss: 0.32812273502349854, Validation Loss: 0.44477224349975586\n","Epoch 3451/5000, Training Loss: 0.3689907193183899, Validation Loss: 0.4085051417350769\n","Epoch 3461/5000, Training Loss: 0.3352610766887665, Validation Loss: 0.39533528685569763\n","Epoch 3471/5000, Training Loss: 0.32533660531044006, Validation Loss: 0.4160846769809723\n","Epoch 3481/5000, Training Loss: 0.3880496621131897, Validation Loss: 0.408107727766037\n","Epoch 3491/5000, Training Loss: 0.3240814208984375, Validation Loss: 0.41378191113471985\n","Epoch 3501/5000, Training Loss: 0.36145099997520447, Validation Loss: 0.42527180910110474\n","Epoch 3511/5000, Training Loss: 0.32096582651138306, Validation Loss: 0.4199889898300171\n","Epoch 3521/5000, Training Loss: 0.2973129451274872, Validation Loss: 0.39916688203811646\n","Epoch 3531/5000, Training Loss: 0.3372659981250763, Validation Loss: 0.39538970589637756\n","Epoch 3541/5000, Training Loss: 0.29907819628715515, Validation Loss: 0.38410159945487976\n","Epoch 3551/5000, Training Loss: 0.2958360016345978, Validation Loss: 0.3876311480998993\n","Epoch 3561/5000, Training Loss: 0.3009457290172577, Validation Loss: 0.39352262020111084\n","Epoch 3571/5000, Training Loss: 0.416293740272522, Validation Loss: 0.4345289170742035\n","Epoch 3581/5000, Training Loss: 0.31339356303215027, Validation Loss: 0.3916635811328888\n","Epoch 3591/5000, Training Loss: 0.31105974316596985, Validation Loss: 0.414856493473053\n","Epoch 3601/5000, Training Loss: 0.3323875367641449, Validation Loss: 0.4291461110115051\n","Epoch 3611/5000, Training Loss: 0.34982702136039734, Validation Loss: 0.44530901312828064\n","Epoch 3621/5000, Training Loss: 0.3941481113433838, Validation Loss: 0.4349069893360138\n","Epoch 3631/5000, Training Loss: 0.2985352873802185, Validation Loss: 0.3909582495689392\n","Epoch 3641/5000, Training Loss: 0.3090910017490387, Validation Loss: 0.4081132709980011\n","Epoch 3651/5000, Training Loss: 0.32987353205680847, Validation Loss: 0.42646485567092896\n","Epoch 3661/5000, Training Loss: 0.3807905614376068, Validation Loss: 0.4265565872192383\n","Epoch 3671/5000, Training Loss: 0.30753767490386963, Validation Loss: 0.39796754717826843\n","Epoch 3681/5000, Training Loss: 0.36982956528663635, Validation Loss: 0.42003002762794495\n","Epoch 3691/5000, Training Loss: 0.3227921426296234, Validation Loss: 0.43021413683891296\n","Epoch 3701/5000, Training Loss: 0.3071625232696533, Validation Loss: 0.39380961656570435\n","Epoch 3711/5000, Training Loss: 0.3137621581554413, Validation Loss: 0.42837560176849365\n","Epoch 3721/5000, Training Loss: 0.32087966799736023, Validation Loss: 0.41585543751716614\n","Epoch 3731/5000, Training Loss: 0.4058702886104584, Validation Loss: 0.46288490295410156\n","Epoch 3741/5000, Training Loss: 0.3061107099056244, Validation Loss: 0.40259966254234314\n","Epoch 3751/5000, Training Loss: 0.2968139052391052, Validation Loss: 0.3833863139152527\n","Epoch 3761/5000, Training Loss: 0.31734511256217957, Validation Loss: 0.414312481880188\n","Epoch 3771/5000, Training Loss: 0.31644144654273987, Validation Loss: 0.4329545199871063\n","Epoch 3781/5000, Training Loss: 0.3183063864707947, Validation Loss: 0.40969258546829224\n","Epoch 3791/5000, Training Loss: 0.30670779943466187, Validation Loss: 0.4081241488456726\n","Epoch 3801/5000, Training Loss: 0.32299718260765076, Validation Loss: 0.41288408637046814\n","Epoch 3811/5000, Training Loss: 0.32575342059135437, Validation Loss: 0.4074694514274597\n","Epoch 3821/5000, Training Loss: 0.3111984431743622, Validation Loss: 0.42039552330970764\n","Epoch 3831/5000, Training Loss: 0.33071982860565186, Validation Loss: 0.4234757423400879\n","Epoch 3841/5000, Training Loss: 0.3638055920600891, Validation Loss: 0.39880383014678955\n","Epoch 3851/5000, Training Loss: 0.3042794466018677, Validation Loss: 0.39636120200157166\n","Epoch 3861/5000, Training Loss: 0.33327537775039673, Validation Loss: 0.4123130440711975\n","Epoch 3871/5000, Training Loss: 0.29839807748794556, Validation Loss: 0.3952760398387909\n","Epoch 3881/5000, Training Loss: 0.2972211241722107, Validation Loss: 0.38590124249458313\n","Epoch 3891/5000, Training Loss: 0.31390902400016785, Validation Loss: 0.39537709951400757\n","Epoch 3901/5000, Training Loss: 0.348816841840744, Validation Loss: 0.4243563711643219\n","Epoch 3911/5000, Training Loss: 0.30722132325172424, Validation Loss: 0.3836289346218109\n","Epoch 3921/5000, Training Loss: 0.30308428406715393, Validation Loss: 0.40697571635246277\n","Epoch 3931/5000, Training Loss: 0.33852848410606384, Validation Loss: 0.3847352862358093\n","Epoch 3941/5000, Training Loss: 0.30477282404899597, Validation Loss: 0.40914854407310486\n","Epoch 3951/5000, Training Loss: 0.3206245005130768, Validation Loss: 0.4210633337497711\n","Epoch 3961/5000, Training Loss: 0.3050817847251892, Validation Loss: 0.401377409696579\n","Epoch 3971/5000, Training Loss: 0.31909874081611633, Validation Loss: 0.4055059850215912\n","Epoch 3981/5000, Training Loss: 0.31844907999038696, Validation Loss: 0.39145103096961975\n","Epoch 3991/5000, Training Loss: 0.3206096291542053, Validation Loss: 0.38731902837753296\n","Epoch 4001/5000, Training Loss: 0.30412793159484863, Validation Loss: 0.40641364455223083\n","Epoch 4011/5000, Training Loss: 0.3197903037071228, Validation Loss: 0.3969995081424713\n","Epoch 4021/5000, Training Loss: 0.2999478578567505, Validation Loss: 0.39244142174720764\n","Epoch 4031/5000, Training Loss: 0.45730477571487427, Validation Loss: 0.43483978509902954\n","Epoch 4041/5000, Training Loss: 0.30827510356903076, Validation Loss: 0.392851859331131\n","Epoch 4051/5000, Training Loss: 0.31895965337753296, Validation Loss: 0.4120880961418152\n","Epoch 4061/5000, Training Loss: 0.3696257472038269, Validation Loss: 0.43580734729766846\n","Epoch 4071/5000, Training Loss: 0.3710947334766388, Validation Loss: 0.3926764130592346\n","Epoch 4081/5000, Training Loss: 0.3428954780101776, Validation Loss: 0.39399227499961853\n","Epoch 4091/5000, Training Loss: 0.3115733563899994, Validation Loss: 0.3866233229637146\n","Epoch 4101/5000, Training Loss: 0.3048022985458374, Validation Loss: 0.39368894696235657\n","Epoch 4111/5000, Training Loss: 0.3035576343536377, Validation Loss: 0.41660162806510925\n","Epoch 4121/5000, Training Loss: 0.3101893961429596, Validation Loss: 0.3953970670700073\n","Epoch 4131/5000, Training Loss: 0.3063192367553711, Validation Loss: 0.40120425820350647\n","Epoch 4141/5000, Training Loss: 0.31404969096183777, Validation Loss: 0.3946090638637543\n","Epoch 4151/5000, Training Loss: 0.3363106846809387, Validation Loss: 0.3893858790397644\n","Epoch 4161/5000, Training Loss: 0.37940847873687744, Validation Loss: 0.44918787479400635\n","Epoch 4171/5000, Training Loss: 0.3255530297756195, Validation Loss: 0.38642293214797974\n","Epoch 4181/5000, Training Loss: 0.3155546486377716, Validation Loss: 0.3882606029510498\n","Epoch 4191/5000, Training Loss: 0.34417349100112915, Validation Loss: 0.3860934376716614\n","Epoch 4201/5000, Training Loss: 0.3053024113178253, Validation Loss: 0.3932368755340576\n","Epoch 4211/5000, Training Loss: 0.33691808581352234, Validation Loss: 0.4297349154949188\n","Epoch 4221/5000, Training Loss: 0.345559298992157, Validation Loss: 0.38717174530029297\n","Epoch 4231/5000, Training Loss: 0.3031255304813385, Validation Loss: 0.4001724421977997\n","Epoch 4241/5000, Training Loss: 0.3003194332122803, Validation Loss: 0.39420971274375916\n","Epoch 4251/5000, Training Loss: 0.3071816563606262, Validation Loss: 0.39831507205963135\n","Epoch 4261/5000, Training Loss: 0.3061905801296234, Validation Loss: 0.40277689695358276\n","Epoch 4271/5000, Training Loss: 0.32002919912338257, Validation Loss: 0.40651190280914307\n","Epoch 4281/5000, Training Loss: 0.33813759684562683, Validation Loss: 0.42755937576293945\n","Epoch 4291/5000, Training Loss: 0.32183805108070374, Validation Loss: 0.41367337107658386\n","Epoch 4301/5000, Training Loss: 0.3098827004432678, Validation Loss: 0.42240405082702637\n","Epoch 4311/5000, Training Loss: 0.3013904392719269, Validation Loss: 0.39176368713378906\n","Epoch 4321/5000, Training Loss: 0.31068673729896545, Validation Loss: 0.40532854199409485\n","Epoch 4331/5000, Training Loss: 0.3242160379886627, Validation Loss: 0.41367805004119873\n","Epoch 4341/5000, Training Loss: 0.3030398190021515, Validation Loss: 0.3887186348438263\n","Epoch 4351/5000, Training Loss: 0.3075439929962158, Validation Loss: 0.39703044295310974\n","Epoch 4361/5000, Training Loss: 0.310494065284729, Validation Loss: 0.38889771699905396\n","Epoch 4371/5000, Training Loss: 0.3211372494697571, Validation Loss: 0.3841925263404846\n","Epoch 4381/5000, Training Loss: 0.3019292652606964, Validation Loss: 0.4013965129852295\n","Epoch 4391/5000, Training Loss: 0.30726948380470276, Validation Loss: 0.3837791979312897\n","Epoch 4401/5000, Training Loss: 0.3119131326675415, Validation Loss: 0.41608259081840515\n","Epoch 4411/5000, Training Loss: 0.30532944202423096, Validation Loss: 0.39547547698020935\n","Epoch 4421/5000, Training Loss: 0.306784451007843, Validation Loss: 0.40201056003570557\n","Epoch 4431/5000, Training Loss: 0.3105582594871521, Validation Loss: 0.3945048749446869\n","Epoch 4441/5000, Training Loss: 0.3348734676837921, Validation Loss: 0.43304455280303955\n","Epoch 4451/5000, Training Loss: 0.30562469363212585, Validation Loss: 0.39883771538734436\n","Epoch 4461/5000, Training Loss: 0.31384995579719543, Validation Loss: 0.4049922227859497\n","Epoch 4471/5000, Training Loss: 0.319659560918808, Validation Loss: 0.3895981013774872\n","Epoch 4481/5000, Training Loss: 0.37016090750694275, Validation Loss: 0.4084371328353882\n","Epoch 4491/5000, Training Loss: 0.31504565477371216, Validation Loss: 0.40708258748054504\n","Epoch 4501/5000, Training Loss: 0.31577375531196594, Validation Loss: 0.39033043384552\n","Epoch 4511/5000, Training Loss: 0.30617204308509827, Validation Loss: 0.4028230607509613\n","Epoch 4521/5000, Training Loss: 0.3192381262779236, Validation Loss: 0.39974111318588257\n","Epoch 4531/5000, Training Loss: 0.30310115218162537, Validation Loss: 0.38910648226737976\n","Epoch 4541/5000, Training Loss: 0.30480125546455383, Validation Loss: 0.4096648097038269\n","Epoch 4551/5000, Training Loss: 0.30622169375419617, Validation Loss: 0.4024822413921356\n","Epoch 4561/5000, Training Loss: 0.3938320577144623, Validation Loss: 0.4104984700679779\n","Epoch 4571/5000, Training Loss: 0.32854408025741577, Validation Loss: 0.40304484963417053\n","Epoch 4581/5000, Training Loss: 0.303945392370224, Validation Loss: 0.4060811698436737\n","Epoch 4591/5000, Training Loss: 0.4012802541255951, Validation Loss: 0.4232829511165619\n","Epoch 4601/5000, Training Loss: 0.3456853926181793, Validation Loss: 0.4165794551372528\n","Epoch 4611/5000, Training Loss: 0.3128410279750824, Validation Loss: 0.3818354904651642\n","Epoch 4621/5000, Training Loss: 0.30289214849472046, Validation Loss: 0.4019685387611389\n","Epoch 4631/5000, Training Loss: 0.31011027097702026, Validation Loss: 0.39455774426460266\n","Epoch 4641/5000, Training Loss: 0.30716055631637573, Validation Loss: 0.38063985109329224\n","Epoch 4651/5000, Training Loss: 0.34183448553085327, Validation Loss: 0.41169512271881104\n","Epoch 4661/5000, Training Loss: 0.30776384472846985, Validation Loss: 0.4066940248012543\n","Epoch 4671/5000, Training Loss: 0.30439284443855286, Validation Loss: 0.4004918932914734\n","Epoch 4681/5000, Training Loss: 0.30556637048721313, Validation Loss: 0.41559842228889465\n","Epoch 4691/5000, Training Loss: 0.30380403995513916, Validation Loss: 0.3889685869216919\n","Epoch 4701/5000, Training Loss: 0.3051133453845978, Validation Loss: 0.3817189633846283\n","Epoch 4711/5000, Training Loss: 0.30427220463752747, Validation Loss: 0.4008966088294983\n","Epoch 4721/5000, Training Loss: 0.3695925772190094, Validation Loss: 0.40559253096580505\n","Epoch 4731/5000, Training Loss: 0.31104907393455505, Validation Loss: 0.38663214445114136\n","Epoch 4741/5000, Training Loss: 0.3065076768398285, Validation Loss: 0.4003578722476959\n","Epoch 4751/5000, Training Loss: 0.31788694858551025, Validation Loss: 0.3877403438091278\n","Epoch 4761/5000, Training Loss: 0.35804158449172974, Validation Loss: 0.4095652997493744\n","Epoch 4771/5000, Training Loss: 0.3298453986644745, Validation Loss: 0.42012152075767517\n","Epoch 4781/5000, Training Loss: 0.3098013699054718, Validation Loss: 0.3812524080276489\n","Epoch 4791/5000, Training Loss: 0.33460476994514465, Validation Loss: 0.38750752806663513\n","Epoch 4801/5000, Training Loss: 0.30748459696769714, Validation Loss: 0.40975573658943176\n","Epoch 4811/5000, Training Loss: 0.31026843190193176, Validation Loss: 0.40882980823516846\n","Epoch 4821/5000, Training Loss: 0.3012104034423828, Validation Loss: 0.38361960649490356\n","Epoch 4831/5000, Training Loss: 0.31798937916755676, Validation Loss: 0.3961520791053772\n","Epoch 4841/5000, Training Loss: 0.33307236433029175, Validation Loss: 0.41971734166145325\n","Epoch 4851/5000, Training Loss: 0.32433098554611206, Validation Loss: 0.42432674765586853\n","Epoch 4861/5000, Training Loss: 0.30354124307632446, Validation Loss: 0.3917934000492096\n","Epoch 4871/5000, Training Loss: 0.3084983825683594, Validation Loss: 0.3775290250778198\n","Epoch 4881/5000, Training Loss: 0.333332359790802, Validation Loss: 0.3856487274169922\n","Epoch 4891/5000, Training Loss: 0.32205069065093994, Validation Loss: 0.4211982488632202\n","Epoch 4901/5000, Training Loss: 0.362326443195343, Validation Loss: 0.4204901158809662\n","Epoch 4911/5000, Training Loss: 0.3049963116645813, Validation Loss: 0.40988242626190186\n","Epoch 4921/5000, Training Loss: 0.3096790015697479, Validation Loss: 0.3915331959724426\n","Epoch 4931/5000, Training Loss: 0.3127381503582001, Validation Loss: 0.42543911933898926\n","Epoch 4941/5000, Training Loss: 0.3169536590576172, Validation Loss: 0.3924683630466461\n","Epoch 4951/5000, Training Loss: 0.30978813767433167, Validation Loss: 0.39053720235824585\n","Epoch 4961/5000, Training Loss: 0.3056983947753906, Validation Loss: 0.3863605558872223\n","Epoch 4971/5000, Training Loss: 0.3409110903739929, Validation Loss: 0.43091627955436707\n","Epoch 4981/5000, Training Loss: 0.3113253712654114, Validation Loss: 0.38954150676727295\n","Epoch 4991/5000, Training Loss: 0.30603575706481934, Validation Loss: 0.38757631182670593\n"]}]},{"cell_type":"markdown","source":["**Feature Importance**\n","\n","The permutation approach to feature importance evaluation may exhibit limitations, because the performance metrics calculated by permuting individual features do not provide meaningful insights into the actual importance of each feature. This is because the order of significance tends to fluctuate across iterations as also shown in the baseline model."],"metadata":{"id":"7K4z2dDS6ap_"}},{"cell_type":"code","source":["def shuffle_column(tensor, column_index):\n","    column_values = tensor[:, column_index]\n","    random_indices = torch.randperm(column_values.size(0))\n","    shuffled_column = column_values[random_indices]\n","    tensor[:, column_index] = shuffled_column\n","    return tensor"],"metadata":{"id":"bQEKZcMA7Znr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compare_importance(model,x_tensor,y_tensor):\n","  loss_compare=np.zeros((x_tensor.shape[1]))\n","  #print(x_tensor.shape[1])\n","  n=1000\n","  loss_each_run=np.zeros((n))\n","  for i in range(x_tensor.shape[1]):\n","    #print(i)\n","    for j in range(n):\n","      shuffled_tensor=shuffle_column(x_tensor, i)\n","      #print(shuffled_tensor)\n","      device = \"cpu\"\n","      if torch.cuda.is_available():\n","          device = \"cuda:0\"\n","      model.to(device)\n","      model.eval()\n","      output = model(x_tensor.to(device))\n","      metric = torch.nn.L1Loss()\n","      loss = metric(output, y_tensor.to(device))\n","      loss_each_run[j]=loss\n","    loss_compare[i]=np.average(loss_each_run)\n","  return loss_compare"],"metadata":{"id":"vgCkpqrO7t77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_compare_val=compare_importance(model_final,x_val_tensor,y_val_tensor)"],"metadata":{"id":"4LEwwf7W7mD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Validation Set: Metric of each feature permutaion ',loss_compare_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kM81ic1_-UE","executionInfo":{"status":"ok","timestamp":1701925031440,"user_tz":360,"elapsed":202,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"aa08e43f-fd3c-4af2-e2c0-529fc30d38a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Set: Metric of each feature permutaion  [0.49326371 0.69135552 0.68347301]\n"]}]},{"cell_type":"markdown","source":["Feature Importance from Baseline Model"],"metadata":{"id":"wNxs_O1Ec2vI"}},{"cell_type":"code","source":["baseline = load('regression_deg9.joblib')"],"metadata":{"id":"CxHrrBK2C3W4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compare_importance_baseline(base,deg,x_tensor,y_tensor):\n","    loss_compare=np.zeros((x_tensor.shape[1]))\n","    #print(x_tensor.shape[1])\n","    n=1000\n","    loss_each_run=np.zeros((n))\n","    for i in range(x_tensor.shape[1]):\n","      #print(i)\n","      for j in range(n):\n","        shuffled_tensor=shuffle_column(x_tensor, i)\n","        #print(shuffled_tensor)\n","        input=shuffled_tensor.numpy()\n","        poly = PolynomialFeatures(degree=deg, include_bias=True)\n","        poly_features_val = poly.fit_transform(input)\n","        pred_Y = base.predict(poly_features_val)\n","        #MSE=mean_squared_error(Yvalidate, pred_Y)\n","        MAE=mean_absolute_error(y_tensor.numpy().reshape(-1), pred_Y)\n","        loss_each_run[j]=MAE\n","      loss_compare[i]=np.average(loss_each_run)\n","    return loss_compare"],"metadata":{"id":"inidCWKxd-OY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_baseline=compare_importance_baseline(baseline,9,x_val_tensor,y_val_tensor)"],"metadata":{"id":"nDCCvKAKgSaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Baseline: Metric of each feature permutaion ',loss_baseline)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySLT5AFrgZ4K","executionInfo":{"status":"ok","timestamp":1701925856643,"user_tz":360,"elapsed":15,"user":{"displayName":"Narathip Rodwarna","userId":"04994885612329167307"}},"outputId":"fdcfef29-3970-469d-b1e5-1ef3d4400d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline: Metric of each feature permutaion  [1.63134968 1.66588419 1.69664181]\n"]}]}]}